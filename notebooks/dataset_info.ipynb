{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se på antall sider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "test_pages = list(\n",
    "    Path(\"../data/transkribus_exports/test_data/2997983/Testsett_Samisk_OCR/\").glob(\"*.jpg\")\n",
    ")\n",
    "train_pages = list(Path(\"../data/transkribus_exports/train_data/train/\").glob(\"**/*.jpg\"))\n",
    "side_30_pages = list(Path(\"../data/transkribus_exports/train_data/side_30/\").glob(\"**/*.jpg\"))\n",
    "gt_pix_pages = list(Path(\"../data/transkribus_exports/train_data/GT_pix\").glob(\"**/*.tif\"))\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "Antall sider trening+validering     {len(train_pages)}\n",
    "Antall sider test                   {len(test_pages)}\n",
    "Antall sider side 30                {len(side_30_pages)}\n",
    "Antall sider GT pix                 {len(gt_pix_pages)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se på antall dokumenter i data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../data/samisk_ocr_dataset/train/_metadata.csv\")\n",
    "manual_train_df = train_df[~train_df.page_30 & ~train_df.gt_pix]\n",
    "page_30_df = train_df[train_df.page_30]\n",
    "gt_pix_df = train_df[train_df.gt_pix]\n",
    "\n",
    "\n",
    "val_df = pd.read_csv(\"../data/samisk_ocr_dataset/val/_metadata.csv\")\n",
    "test_df = pd.read_csv(\"../data/samisk_ocr_dataset/test/_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "Antall dokumenter \n",
    "Trening         {len(manual_train_df.urn.unique())}\n",
    "Validering      {len(val_df.urn.unique())}\n",
    "Test            {len(test_df.urn.unique())}\n",
    "----\n",
    "GT pix          {len(gt_pix_df.urn.unique())}\n",
    "Side 30         {len(page_30_df.urn.unique())}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Språkvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def print_language_overview(df: pd.DataFrame):\n",
    "    lang_line_len = defaultdict(int)\n",
    "    lang_page_len = defaultdict(int)\n",
    "    lang_doc_len = defaultdict(int)\n",
    "    total_pages = 0\n",
    "    for langcodes, df_ in df.groupby(\"langcodes\"):\n",
    "        num_pages = 0\n",
    "        for _, df__ in df_.groupby(\"urn\"):\n",
    "            num_pages += len(df__.page.unique())\n",
    "        total_pages += num_pages\n",
    "\n",
    "        langcodes = literal_eval(langcodes)\n",
    "        if len(langcodes) > 1:\n",
    "            for langcode in langcodes:\n",
    "                lang_line_len[langcode] += len(df_) / 2\n",
    "                lang_doc_len[langcode] += len(df_.urn.unique()) / 2\n",
    "                lang_page_len[langcode] += num_pages / 2\n",
    "        else:\n",
    "            lang_line_len[langcodes[0]] += len(df_)\n",
    "            lang_doc_len[langcodes[0]] += len(df_.urn.unique())\n",
    "            lang_page_len[langcodes[0]] += num_pages\n",
    "\n",
    "    for lang, num in lang_doc_len.items():\n",
    "        print(f\"Språk: {lang}\")\n",
    "        print(f\"    Antall dokumenter:  {num} ({round(num/len(df.urn.unique())*100, 2)}%)\")\n",
    "        print(\n",
    "            f\"    Antall sider:       {lang_page_len[lang]} ({round(lang_page_len[lang]/total_pages*100, 2)}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"    Antall linjer:      {lang_line_len[lang]} ({round(lang_line_len[lang]/len(df)*100, 2)}%)\"\n",
    "        )\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Treningssett språkoversikt\\n\")\n",
    "print_language_overview(manual_train_df)\n",
    "\n",
    "print(\"Valideringssett språkoversikt\\n\")\n",
    "print_language_overview(val_df)\n",
    "\n",
    "print(\"Side 30 språkoversikt\\n\")\n",
    "print_language_overview(page_30_df)\n",
    "\n",
    "print(\"Testsett språkoversikt\\n\")\n",
    "print_language_overview(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from nb_tokenizer import tokenize\n",
    "\n",
    "\n",
    "def get_tokens(df: pd.DataFrame) -> Counter[str]:\n",
    "    tokens = [t for text_line in df.text for t in tokenize(str(text_line))]\n",
    "    return Counter(tokens)\n",
    "\n",
    "\n",
    "train_tokens = get_tokens(manual_train_df)\n",
    "s_30_tokens = get_tokens(page_30_df)\n",
    "gt_pix_tokens = get_tokens(gt_pix_df)\n",
    "val_tokens = get_tokens(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Unike tokens:\n",
    "    Train:      {'{:_}'.format(len(train_tokens))}\n",
    "    Val:        {'{:_}'.format(len(val_tokens))}\n",
    "    Side 30:    {'{:_}'.format(len(s_30_tokens))}\n",
    "    GT pix:     {'{:_}'.format(len(gt_pix_tokens))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Totalt antall tokens:\n",
    "    Train:      {'{:_}'.format(sum(train_tokens.values()))}\n",
    "    Side 30:    {'{:_}'.format(sum(s_30_tokens.values()))}\n",
    "    Val:        {'{:_}'.format(sum(val_tokens.values()))}\n",
    "    GT pix:     {'{:_}'.format(sum(gt_pix_tokens.values()))}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Iterable\n",
    "\n",
    "\n",
    "def percent_overlap(container1: Iterable[Any], container2: Iterable[Any]) -> float:\n",
    "    intersection_len = len(set(container1).intersection(set(container2)))\n",
    "    intersection_part = intersection_len / len(container1)\n",
    "    return round(intersection_part * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Tokenoverlapp\n",
    "      \n",
    "    Train og val:      \n",
    "        {percent_overlap(val_tokens, train_tokens)}% av tokensa i val finnes i train\n",
    "        {percent_overlap(train_tokens, val_tokens)}% av tokensa i train finnes i val\n",
    "\n",
    "    Train og side 30:   \n",
    "        {percent_overlap(train_tokens, s_30_tokens)}% av tokensa i train finnes i side 30\n",
    "        {percent_overlap(s_30_tokens, train_tokens)}% av tokensa i side 30 finnes i train \n",
    "        \n",
    "    Val og side 30:   \n",
    "        {percent_overlap(val_tokens, s_30_tokens)}% av tokensa i val finnes i side 30\n",
    "        {percent_overlap(s_30_tokens, val_tokens)}% av tokensa i side 30 finnes i val       \n",
    "-----\n",
    "    Train og GT pix:   \n",
    "        {percent_overlap(train_tokens, gt_pix_tokens)}% av tokensa i train finnes i GT pix\n",
    "        {percent_overlap(gt_pix_tokens, train_tokens)}% av tokensa i GT pix finnes i train \n",
    "        \n",
    "    Val og GT pix:   \n",
    "        {percent_overlap(val_tokens, gt_pix_tokens)}% av tokensa i val finnes i GT pix\n",
    "        {percent_overlap(gt_pix_tokens, val_tokens)}% av tokensa i GT pix finnes i val       \n",
    "      \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forskjeller i tokens mellom settene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Antall tokens som bare fins i side 30:    {len(set(s_30_tokens) - (set(train_tokens).union(set(val_tokens).union(set(gt_pix_tokens)))))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Antall tokens som bare fins i GT pix:     {len(set(gt_pix_tokens) - set(s_30_tokens).union(set(train_tokens)).union(set(val_tokens)))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Antall tokens som bare fins i train:      {len(set(train_tokens) - set(s_30_tokens).union(set(val_tokens)).union(set(gt_pix_tokens)))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Antall tokens som bare fins i val:        {len(set(val_tokens) - set(s_30_tokens).union(set(train_tokens)).union(set(gt_pix_tokens)))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from samisk_ocr.write_characters import get_text\n",
    "\n",
    "train_text = get_text(manual_train_df)\n",
    "train_cloud = WordCloud().generate(train_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(train_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text = get_text(val_df)\n",
    "val_cloud = WordCloud().generate(val_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(val_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_30_text = get_text(page_30_df)\n",
    "p_30_cloud = WordCloud().generate(p_30_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(p_30_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pix_text = get_text(gt_pix_df)\n",
    "gt_pix_cloud = WordCloud().generate(gt_pix_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(gt_pix_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se på bokstaver og tegn i data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars = Counter(train_text)\n",
    "s_30_chars = Counter(p_30_text)\n",
    "val_chars = Counter(val_text)\n",
    "gt_pix_chars = Counter(gt_pix_text)\n",
    "test_chars = Counter(get_text(test_df))\n",
    "\n",
    "print(f\"\"\"Unike tegn:\n",
    "    Train:      {'{:_}'.format(len(train_chars))}\n",
    "    Val:        {'{:_}'.format(len(val_chars))}\n",
    "    Side 30:    {'{:_}'.format(len(s_30_chars))}\n",
    "    GT pix:     {'{:_}'.format(len(gt_pix_chars))}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"Totalt antall tegn:\n",
    "    Train:      {'{:_}'.format(sum(train_chars.values()))}\n",
    "    Side 30:    {'{:_}'.format(sum(s_30_chars.values()))}\n",
    "    Val:        {'{:_}'.format(sum(val_chars.values()))}\n",
    "    GT pix:     {'{:_}'.format(sum(gt_pix_chars.values()))}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"Tegnoverlapp\n",
    "      \n",
    "    Train og val:      \n",
    "        {percent_overlap(val_chars, train_chars)}% av tegna i val finnes i train\n",
    "        {percent_overlap(train_chars, val_chars)}% av tegna i train finnes i val\n",
    "\n",
    "    Train og side 30:   \n",
    "        {percent_overlap(train_chars, s_30_chars)}% av tegna i train finnes i side 30\n",
    "        {percent_overlap(s_30_chars, train_chars)}% av tegna i side 30 finnes i train \n",
    "\n",
    "    Val og side 30:   \n",
    "        {percent_overlap(val_chars, s_30_chars)}% av tegna i val finnes i side 30\n",
    "        {percent_overlap(s_30_chars, val_chars)}% av tegna i side 30 finnes i val   \n",
    "\n",
    "----\n",
    "\n",
    "    Train og GT pix:   \n",
    "        {percent_overlap(train_chars, gt_pix_chars)}% av tegna i train finnes i GT pix\n",
    "        {percent_overlap(gt_pix_chars, train_chars)}% av tegna i GT pix finnes i train       \n",
    "      \n",
    "\n",
    "    Val og GT pix:   \n",
    "        {percent_overlap(val_chars, gt_pix_chars)}% av tegna i val finnes i GT pix\n",
    "        {percent_overlap(gt_pix_chars, val_chars)}% av tegna i GT pix finnes i val       \n",
    "      \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forskjeller i tegn mellom settene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Bare i side 30: {list(set(s_30_chars) - (set(train_chars).union(set(val_chars)).union(set(gt_pix_chars))))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Bare i train {list(set(train_chars) - set(s_30_chars).union(set(val_chars)).union(gt_pix_chars))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Bare i val {list(set(val_chars) - set(s_30_chars).union(set(train_chars)).union(gt_pix_chars))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Bare i GT pix {list(set(gt_pix_chars) - set(s_30_chars).union(set(train_chars)).union(val_chars))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmmm hvorfor er D med strek bare i train OG bare i val?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elfdal_d = \"Ð\"\n",
    "african_d = \"Ɖ\"\n",
    "skolt_d = \"Đ\"\n",
    "\n",
    "assert elfdal_d != african_d != skolt_d\n",
    "\n",
    "print(val_chars[elfdal_d], train_chars[elfdal_d])\n",
    "print(val_chars[african_d], train_chars[african_d])\n",
    "print(val_chars[skolt_d], train_chars[skolt_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = sorted(list(set(train_chars).union(set(val_chars))))\n",
    "unicode_code_points = [f\"{ord(char):04X}\" for char in all_chars]\n",
    "links = [\n",
    "    f\"https://util.unicode.org/UnicodeJsps/character.jsp?a={code_point}\"\n",
    "    for code_point in unicode_code_points\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = [val_chars[char] for char in all_chars]\n",
    "train_counts = [train_chars[char] for char in all_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"tegn\": all_chars,\n",
    "        \"link\": links,\n",
    "        \"antall_forekomster_train\": train_counts,\n",
    "        \"antall_forekomster_val\": val_counts,\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tegn_og_bokstaver.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upper = Counter({char: count for char, count in train_chars.items() if char.isupper()})\n",
    "train_lower = Counter({char: count for char, count in train_chars.items() if char.islower()})\n",
    "val_upper = Counter({char: count for char, count in val_chars.items() if char.isupper()})\n",
    "val_lower = Counter({char: count for char, count in val_chars.items() if char.islower()})\n",
    "s30_upper = Counter({char: count for char, count in s_30_chars.items() if char.isupper()})\n",
    "s30_lower = Counter({char: count for char, count in s_30_chars.items() if char.islower()})\n",
    "gt_pix_upper = Counter({char: count for char, count in gt_pix_chars.items() if char.isupper()})\n",
    "gt_pix_lower = Counter({char: count for char, count in gt_pix_chars.items() if char.islower()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_upper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se på ord i data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ordbilder.annotations import get_annotation_information\n",
    "from samisk_ocr.clean_text_data import clean\n",
    "from pathlib import Path\n",
    "\n",
    "train_path = Path(\"../data/transkribus_exports/train_data/train\")\n",
    "s_30_path = Path(\"../data/transkribus_exports/train_data/side_30\")\n",
    "test_path = Path(\"../data/transkribus_exports/test_data/2997983/Testsett_Samisk_OCR\")\n",
    "\n",
    "\n",
    "# Lag txt-mappe hvis ikke finnes\n",
    "for path in (train_path, s_30_path, test_path):\n",
    "    was_unclean = 0\n",
    "    num_pages = 0\n",
    "    for alto_dir in path.glob(\"**/alto\"):\n",
    "        files = list(alto_dir.glob(\"*.xml\"))\n",
    "        text_dir = alto_dir.parent / \"txt\"\n",
    "        text_dir.mkdir(exist_ok=True)\n",
    "        for xml_file in files:\n",
    "            num_pages += 1\n",
    "            page_file = text_dir / f\"{xml_file.stem}.txt\"\n",
    "            annotations = get_annotation_information(xml_path=xml_file)\n",
    "            page_text_pre = \"\\n\".join([e[\"word\"] for e in annotations])\n",
    "            page_text = clean(page_text_pre)\n",
    "            if page_text != page_text_pre:\n",
    "                was_unclean += 1\n",
    "            with page_file.open(\"w+\") as f:\n",
    "                f.write(page_text)\n",
    "    print(\n",
    "        f\"I {path.name} var det {was_unclean} sider (av {num_pages} totalt) med uønskede tegn (non-breaking space og em-dash)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_tokenizer import tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_tokens(directory: Path) -> Counter[str]:\n",
    "    tokens = []\n",
    "    for text_dir in directory.glob(\"**/txt\"):\n",
    "        text_files = text_dir.glob(\"*.txt\")\n",
    "        texts = \" \".join([e.read_text() for e in text_files])\n",
    "        tokens += tokenize(texts)\n",
    "    return Counter(tokens)\n",
    "\n",
    "\n",
    "train_tokens = get_tokens(train_path)\n",
    "test_tokens = get_tokens(test_path)\n",
    "s_30_tokens = get_tokens(s_30_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Unike tokens:\n",
    "    Train:      {'{:_}'.format(len(train_tokens))}\n",
    "    Side 30:    {'{:_}'.format(len(s_30_tokens))}\n",
    "    Test:       {'{:_}'.format(len(test_tokens))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Totalt antall tokens:\n",
    "    Train:      {'{:_}'.format(sum(train_tokens.values()))}\n",
    "    Side 30:    {'{:_}'.format(sum(s_30_tokens.values()))}\n",
    "    Test:       {'{:_}'.format(sum(test_tokens.values()))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Any\n",
    "\n",
    "\n",
    "def percent_overlap(container1: Iterable[Any], container2: Iterable[Any]) -> float:\n",
    "    intersection_len = len(set(container1).intersection(set(container2)))\n",
    "    intersection_part = intersection_len / len(container1)\n",
    "    return round(intersection_part * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Tokenoverlapp\n",
    "      \n",
    "    Train og test:      \n",
    "        {percent_overlap(test_tokens, train_tokens)}% av tokensa i test finnes i train\n",
    "        {percent_overlap(train_tokens, test_tokens)}% av tokensa i train finnes i test\n",
    "\n",
    "    Train og side 30:   \n",
    "        {percent_overlap(train_tokens, s_30_tokens)}% av tokensa i train finnes i side 30\n",
    "        {percent_overlap(s_30_tokens, train_tokens)}% av tokensa i side 30 finnes i train \n",
    "\n",
    "    Test og side 30:   \n",
    "        {percent_overlap(test_tokens, s_30_tokens)}% av tokensa i test finnes i side 30\n",
    "        {percent_overlap(s_30_tokens, test_tokens)}% av tokensa i side 30 finnes i test       \n",
    "      \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forskjeller i tokens mellom settene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Antall tokens som bare fins i side 30:  {len(set(s_30_tokens) - (set(train_tokens).union(set(test_tokens))))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Antall tokens som bare fins i train:    {len(set(train_tokens) - set(s_30_tokens).union(set(test_tokens)))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Antall tokens som bare fins i test:     {len(set(test_tokens) - set(s_30_tokens).union(set(train_tokens)))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "def get_text(directory: Path) -> str:\n",
    "    text = \"\"\n",
    "    for text_dir in directory.glob(\"**/txt\"):\n",
    "        text_files = text_dir.glob(\"*.txt\")\n",
    "        texts = \" \".join([e.read_text() for e in text_files])\n",
    "        text += texts\n",
    "    return text\n",
    "\n",
    "\n",
    "train_text = get_text(train_path)\n",
    "train_cloud = WordCloud().generate(train_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(train_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = get_text(test_path)\n",
    "test_cloud = WordCloud().generate(test_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(test_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_30_text = get_text(s_30_path)\n",
    "s_30_cloud = WordCloud().generate(s_30_text)\n",
    "plt.figure(figsize=(60, 20))\n",
    "plt.imshow(s_30_cloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se på bokstaver og tegn i data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars = Counter(train_text)\n",
    "s_30_chars = Counter(s_30_text)\n",
    "test_chars = Counter(test_text)\n",
    "\n",
    "print(f\"\"\"Unike tegn:\n",
    "    Train:      {'{:_}'.format(len(train_chars))}\n",
    "    Side 30:    {'{:_}'.format(len(s_30_chars))}\n",
    "    Test:       {'{:_}'.format(len(test_chars))}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"Totalt antall tegn:\n",
    "    Train:      {'{:_}'.format(sum(train_chars.values()))}\n",
    "    Side 30:    {'{:_}'.format(sum(s_30_chars.values()))}\n",
    "    Test:       {'{:_}'.format(sum(test_chars.values()))}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"Tegnoverlapp\n",
    "      \n",
    "    Train og test:      \n",
    "        {percent_overlap(test_chars, train_chars)}% av tegna i test finnes i train\n",
    "        {percent_overlap(train_chars, test_chars)}% av tegna i train finnes i test\n",
    "\n",
    "    Train og side 30:   \n",
    "        {percent_overlap(train_chars, s_30_chars)}% av tegna i train finnes i side 30\n",
    "        {percent_overlap(s_30_chars, train_chars)}% av tegna i side 30 finnes i train \n",
    "\n",
    "    Test og side 30:   \n",
    "        {percent_overlap(test_chars, s_30_chars)}% av tegna i test finnes i side 30\n",
    "        {percent_overlap(s_30_chars, test_chars)}% av tegna i side 30 finnes i test       \n",
    "      \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forskjeller i tegn mellom settene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Bare i side 30: {list(set(s_30_chars) - (set(train_chars).union(set(test_chars))))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bare i train {list(set(train_chars) - set(s_30_chars).union(set(test_chars)))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_split = pd.read_csv(\"../../data/samisk_ocr_dataset/train/_metadata.csv\")\n",
    "train_split = train_split[\n",
    "    (train_split.page_30 == False) & (train_split.gt_pix == False)\n",
    "]\n",
    "val_split = pd.read_csv(\"../../data/samisk_ocr_dataset/val/_metadata.csv\")\n",
    "test_split = pd.read_csv(\"../../data/new_testset_with_newspapers/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 2035, 871)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines = len(train_split)\n",
    "val_lines = len(val_split)\n",
    "test_lines = len(test_split)\n",
    "\n",
    "train_lines, val_lines, test_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn\n",
      "page\n"
     ]
    }
   ],
   "source": [
    "for e in train_split[[\"urn\", \"page\"]]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train split</th>\n",
       "      <th>val split</th>\n",
       "      <th>test split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Inari\\\\Sámi</th>\n",
       "      <td>2.5 docs\\\\21.0 pages\\\\280.0 lines</td>\n",
       "      <td>3 docs\\\\3 pages\\\\109 lines</td>\n",
       "      <td>5 docs\\\\6 pages\\\\163 lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lule\\\\Sámi</th>\n",
       "      <td>2 docs\\\\4 pages\\\\81 lines</td>\n",
       "      <td>2 docs\\\\2 pages\\\\36 lines</td>\n",
       "      <td>4 docs\\\\4 pages\\\\137 lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North\\\\Sámi</th>\n",
       "      <td>2.5 docs\\\\37.0 pages\\\\5572.0 lines</td>\n",
       "      <td>8 docs\\\\18 pages\\\\1837 lines</td>\n",
       "      <td>7 docs\\\\7 pages\\\\376 lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South\\\\Sámi</th>\n",
       "      <td>5 docs\\\\9 pages\\\\208 lines</td>\n",
       "      <td>2 docs\\\\2 pages\\\\53 lines</td>\n",
       "      <td>4 docs\\\\4 pages\\\\195 lines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    train split                     val split  \\\n",
       "language                                                                        \n",
       "Inari\\\\Sámi   2.5 docs\\\\21.0 pages\\\\280.0 lines    3 docs\\\\3 pages\\\\109 lines   \n",
       "Lule\\\\Sámi            2 docs\\\\4 pages\\\\81 lines     2 docs\\\\2 pages\\\\36 lines   \n",
       "North\\\\Sámi  2.5 docs\\\\37.0 pages\\\\5572.0 lines  8 docs\\\\18 pages\\\\1837 lines   \n",
       "South\\\\Sámi          5 docs\\\\9 pages\\\\208 lines     2 docs\\\\2 pages\\\\53 lines   \n",
       "\n",
       "                             test split  \n",
       "language                                 \n",
       "Inari\\\\Sámi  5 docs\\\\6 pages\\\\163 lines  \n",
       "Lule\\\\Sámi   4 docs\\\\4 pages\\\\137 lines  \n",
       "North\\\\Sámi  7 docs\\\\7 pages\\\\376 lines  \n",
       "South\\\\Sámi  4 docs\\\\4 pages\\\\195 lines  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_language_overview(df: pd.DataFrame):\n",
    "    lang_docs = defaultdict(int)\n",
    "    lang_pages = defaultdict(int)\n",
    "    lang_lines = defaultdict(int)\n",
    "\n",
    "    for langcodes, df_ in df.groupby(\"langcodes\"):\n",
    "        langcodes = literal_eval(langcodes)\n",
    "        num_docs = len(df_.urn.unique())\n",
    "        num_lines = len(df_)\n",
    "        num_pages = len({(urn, page) for urn, page in zip(df_.urn, df_.page)})\n",
    "\n",
    "        if len(langcodes) > 1:\n",
    "            num_langs = 2\n",
    "            assert len(langcodes) == num_langs\n",
    "            for lang in langcodes:\n",
    "                lang_pages[lang] += num_pages / num_langs\n",
    "                lang_lines[lang] += num_lines / num_langs\n",
    "                lang_docs[lang] += num_docs / num_langs\n",
    "\n",
    "        else:\n",
    "            lang = langcodes[0]\n",
    "            lang_pages[lang] += num_pages\n",
    "            lang_lines[lang] += num_lines\n",
    "            lang_docs[lang] += num_docs\n",
    "\n",
    "    return (lang_docs, lang_pages, lang_lines)\n",
    "\n",
    "\n",
    "langcode_map = {\n",
    "    \"smn\": r\"Inari\\\\Sámi\",\n",
    "    \"smj\": r\"Lule\\\\Sámi\",\n",
    "    \"sme\": r\"North\\\\Sámi\",\n",
    "    \"sma\": r\"South\\\\Sámi\",\n",
    "}\n",
    "\n",
    "data_df = pd.DataFrame(\n",
    "    {\n",
    "        \"language\": langcode_map.values(),\n",
    "        \"train split\": [\"\"] * len(langcode_map),\n",
    "        \"val split\": [\"\"] * len(langcode_map),\n",
    "        \"test split\": [\"\"] * len(langcode_map),\n",
    "    }\n",
    ")\n",
    "data_df = data_df.set_index(\"language\")\n",
    "\n",
    "\n",
    "for split, df in (\n",
    "    (\"train split\", train_split),\n",
    "    (\"val split\", val_split),\n",
    "    (\"test split\", test_split),\n",
    "):\n",
    "    doc_counts, page_counts, line_counts = get_language_overview(df)\n",
    "    tot_doc_counts = sum(doc_counts.values())\n",
    "    tot_page_counts = sum(page_counts.values())\n",
    "    tot_line_counts = sum(line_counts.values())\n",
    "\n",
    "    for langcode in langcode_map:\n",
    "        data_str = rf\"{doc_counts[langcode]} docs\\\\{page_counts[langcode]} pages\\\\{line_counts[langcode]} lines\"\n",
    "        data_df.at[langcode_map[langcode], split] = data_str\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      " & train split & val split & test split \\\\\n",
      "language &  &  &  \\\\\n",
      "\\midrule\n",
      "Inari\\\\Sámi & 2.5 docs\\\\21.0 pages\\\\280.0 lines & 3 docs\\\\3 pages\\\\109 lines & 5 docs\\\\6 pages\\\\163 lines \\\\\n",
      "Lule\\\\Sámi & 2 docs\\\\4 pages\\\\81 lines & 2 docs\\\\2 pages\\\\36 lines & 4 docs\\\\4 pages\\\\137 lines \\\\\n",
      "North\\\\Sámi & 2.5 docs\\\\37.0 pages\\\\5572.0 lines & 8 docs\\\\18 pages\\\\1837 lines & 7 docs\\\\7 pages\\\\376 lines \\\\\n",
      "South\\\\Sámi & 5 docs\\\\9 pages\\\\208 lines & 2 docs\\\\2 pages\\\\53 lines & 4 docs\\\\4 pages\\\\195 lines \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_df.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

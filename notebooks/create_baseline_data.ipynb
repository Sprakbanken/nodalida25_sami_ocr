{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5e0be2-3836-400f-a0dc-9819f1876e50",
   "metadata": {},
   "source": [
    "# Evaluering av transkripsjoner fra evalueringsløpya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450b22b-6db6-4950-b1d7-03e2893333f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import ChainMap\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from difflib import HtmlDiff\n",
    "import io\n",
    "from math import floor, ceil\n",
    "\n",
    "\n",
    "import lxml.etree\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from samisk_ocr.clean_text_data import clean\n",
    "import samisk_ocr.trocr\n",
    "from samisk_ocr.metrics import compute_cer, compute_wer, SpecialCharacterF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb86dbd-0708-4542-a59e-85d3713c1e26",
   "metadata": {},
   "source": [
    "## Last data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7beecfa-3b8b-436f-8753-e0bca1287393",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data/new_testset_with_newspapers/metadata.csv\")\n",
    "\n",
    "test_metadata = metadata.query(\"file_name.str.startswith('test')\")\n",
    "\n",
    "del metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314973f-4c07-4895-915d-88fe4d4bc7f5",
   "metadata": {},
   "source": [
    "## Hent transkripsjonen fra ALTO filene og sammenstill med datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041e931-5fbd-4c37-9600-1f4e1fa56685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path: Path) -> io.BytesIO:\n",
    "    return io.BytesIO(path.read_bytes())\n",
    "\n",
    "@lru_cache(30)\n",
    "def load_image(path: Path) -> Image.Image:\n",
    "    return Image.open(load_file(path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14f275-b332-412f-bf14-5465a904851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = {\n",
    "    \"sma\": \"Sørsamisk\",\n",
    "    \"sme\": \"Nordsamisk\",\n",
    "    \"smj\": \"Lulesamisk\",\n",
    "    \"smn\": \"Inaresamisk\",\n",
    "}\n",
    "\n",
    "def urn_col_to_alto_dirname(urncol: str) -> str:\n",
    "    out = urncol.removeprefix(\"URN_NBN_no-nb_\").removeprefix(\"no-nb_digavis_\").removesuffix(\"-1\")\n",
    "    if \"monografi\" in out:\n",
    "        return out + \"_ocr\"\n",
    "    if \"digibok\" in out:\n",
    "        return out + \"_ocr_xml\"\n",
    "    return out.removeprefix(\"no-nb_digavis_\") + \"_ocr_xml\"\n",
    "\n",
    "\n",
    "def urn_col_to_alto_dir(urncol: str) -> Path:\n",
    "    return Path(\"../data/alto\") / urn_col_to_alto_dirname(urncol)\n",
    "\n",
    "\n",
    "def add_page_to_urn(urn: str, page: int) -> str:\n",
    "    alto_dirname = urn.removesuffix(\"_xml\").removesuffix(\"_ocr\").removeprefix(\"URN_NBN_no-nb_\")\n",
    "    if \"pliktmonografi\" in alto_dirname or \"digibok\" in alto_dirname:\n",
    "        return f\"{alto_dirname}_{page:04.0f}.xml\"\n",
    "    alto_dirname = alto_dirname.removeprefix(\"no-nb_digavis_\")\n",
    "    return f\"{alto_dirname}_{page:03.0f}_null.xml\"\n",
    "\n",
    "\n",
    "def get_alto_file(df: pd.DataFrame) -> str:\n",
    "    return df[\"alto_dir\"] / df.apply(\n",
    "        lambda row: add_page_to_urn(row[\"urn\"], row[\"page\"]), axis=\"columns\"\n",
    "    ).rename(\"alto_file\")\n",
    "\n",
    "\n",
    "def get_jp2_file(alto_file: str | Path) -> str:\n",
    "    alto_file = Path(alto_file)\n",
    "    filename = alto_file.with_suffix(\".jp2\").name\n",
    "    folder_name = alto_file.parent.name.removesuffix(\"ocr_xml\") + \"jp2\"\n",
    "    return Path(\"../data\") / \"alto-jp2\" / folder_name / filename\n",
    "\n",
    "def get_bbox(tag) -> tuple[float, float, float, float]:\n",
    "    return (\n",
    "        int(tag.get(\"HPOS\")),\n",
    "        int(tag.get(\"VPOS\")),\n",
    "        int(tag.get(\"HPOS\")) + int(tag.get(\"WIDTH\")),\n",
    "        int(tag.get(\"VPOS\")) + int(tag.get(\"HEIGHT\")),\n",
    "    )\n",
    "\n",
    "def get_surrounding_bbox(bboxes: list[tuple[int, int, int, int]]) -> tuple[int, int, int, int]:\n",
    "    return (\n",
    "        min(bbox[0] for bbox in bboxes),\n",
    "        min(bbox[1] for bbox in bboxes),\n",
    "        max(bbox[2] for bbox in bboxes),\n",
    "        max(bbox[3] for bbox in bboxes),\n",
    "    )\n",
    "        \n",
    "\n",
    "def get_scales(text_block) -> tuple[float, float, float, float]:\n",
    "    x1, y1, x2, y2 = get_bbox(text_block)\n",
    "    x1_, y1_, x2_, y2_ = get_surrounding_bbox([get_bbox(line) for line in text_block.xpath(\"TextLine\")])\n",
    "\n",
    "    def clean_scale(s):\n",
    "        if abs(s - 1) < 0.3:\n",
    "            return 1\n",
    "        if abs(s - 2) < 0.3:\n",
    "            return 2\n",
    "        return s\n",
    "\n",
    "    from statistics import median\n",
    "    return tuple(\n",
    "        s#clean_scale(s)\n",
    "        for s in (x1/x1_, y1/y1_, x2/x2_, y2/y2_)\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "@lru_cache(1000)\n",
    "def get_alto_textlines(alto_file: Path) -> list[str]:\n",
    "    # Parse the XML file\n",
    "    tree = lxml.etree.parse(alto_file)\n",
    "    \n",
    "    # Find all TextLine elements\n",
    "    text_lines = tree.xpath('//TextLine')\n",
    "    \n",
    "    # Initialize an empty list to store the concatenated strings\n",
    "    concatenated_strings = []\n",
    "    bboxes = []\n",
    "\n",
    "    prev_parent = None\n",
    "    # Iterate over each TextLine element\n",
    "    for text_line in text_lines:\n",
    "        # Find all String elements within the current TextLine\n",
    "        strings = text_line.xpath('.//String')\n",
    "        # Extract the CONTENT attribute from each String element and join them with spaces\n",
    "        concatenated_content = ' '.join(string.get('CONTENT') for string in strings)\n",
    "        \n",
    "        # Check if the last element is an HYP tag\n",
    "        last_element = text_line.xpath('.//String|.//HYP')[-1]\n",
    "        if last_element.tag == 'HYP':\n",
    "            concatenated_content += last_element.get('CONTENT', '')\n",
    "        \n",
    "        # Append the concatenated content to the list\n",
    "        concatenated_strings.append(concatenated_content)\n",
    "\n",
    "        # Get the bounding box for the TextLine\n",
    "        parent = text_line.getparent()\n",
    "        scales = get_scales(parent)\n",
    "        if prev_parent != parent:\n",
    "            print(scales)\n",
    "        prev_parent = parent\n",
    "        bbox = get_bbox(text_line)\n",
    "        bboxes.append(tuple(\n",
    "            s * x for s, x in zip(scales, bbox)\n",
    "        ))\n",
    "        if bboxes[-1][0] == bboxes[-1][2] or bboxes[-1][1] == bboxes[-1][3]:\n",
    "            if len(parent.xpath(\"TextLine\")) == 1:\n",
    "                bboxes[-1] = (\n",
    "                    int(parent.get(\"HPOS\")),\n",
    "                    int(parent.get(\"VPOS\")),\n",
    "                    int(parent.get(\"HPOS\")) + int(parent.get(\"WIDTH\")),\n",
    "                    int(parent.get(\"VPOS\")) + int(parent.get(\"HEIGHT\")),\n",
    "                )\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    right_margin = next(iter(tree.xpath(\"//RightMargin\")))\n",
    "    bottom_margin = next(iter(tree.xpath(\"//BottomMargin\")))\n",
    "    width = int(right_margin.get(\"HPOS\")) + int(right_margin.get(\"WIDTH\"))\n",
    "    height = int(bottom_margin.get(\"VPOS\")) + int(bottom_margin.get(\"HEIGHT\"))\n",
    "    # Print the result\n",
    "    return concatenated_strings, bboxes, (width, height)\n",
    "\n",
    "def get_alto_transcription(alto_file, text):\n",
    "    if not alto_file.exists():\n",
    "        return pd.NA\n",
    "    text_lines, bboxes, size = get_alto_textlines(alto_file)\n",
    "    cleaned_text_lines = [clean(l) for l in text_lines]\n",
    "    \n",
    "    selected_line = min(cleaned_text_lines, key=lambda l: compute_cer(text, l))\n",
    "    return selected_line, dict(zip(cleaned_text_lines, bboxes))[selected_line], size\n",
    "\n",
    "def compute_alto_cer(row):\n",
    "    return compute_cer(row[\"text\"], row[\"transcription\"])\n",
    "\n",
    "def compute_alto_wer(row):\n",
    "    return compute_wer(row[\"text\"], row[\"transcription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ccabef-12df-4b4b-9f3a-9311e31972f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = test_metadata.assign(\n",
    "    alto_dir = test_metadata[\"urn\"].map(urn_col_to_alto_dir)\n",
    ").assign(\n",
    "    alto_file=get_alto_file\n",
    ").assign(\n",
    "    transcription=lambda df: df.apply(lambda row: get_alto_transcription(row['alto_file'], row['text'])[0], axis=\"columns\"),\n",
    "    bbox=lambda df: df.apply(lambda row: get_alto_transcription(row['alto_file'], row['text'])[1], axis=\"columns\"),\n",
    "    img_size=lambda df: df.apply(lambda row: get_alto_transcription(row['alto_file'], row['text'])[2], axis=\"columns\"),\n",
    ").assign(\n",
    "    cer=lambda df: df.apply(compute_alto_cer, axis=\"columns\"),\n",
    "    wer=lambda df: df.apply(compute_alto_wer, axis=\"columns\")\n",
    ").assign(\n",
    "    pliktmonografi=lambda df: df[\"file_name\"].str.contains(\"pliktmonografi\")\n",
    ").assign(\n",
    "    language=lambda df: df[\"langcodes\"].map(lambda s: LANGUAGES[s.removeprefix(\"['\").removesuffix(\"']\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4322b9-693e-438e-a09d-f271fdc8ac3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616d9af-98cd-4bc2-865e-05c7b54e8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(path: Path, bbox: tuple[int, int, int, int], ocr_img_size: tuple[int, int]) -> Image.Image:\n",
    "    img = load_image(path)\n",
    "    img_w = img.size[0]\n",
    "    ocr_w = ocr_img_size[0]\n",
    "    aspect_ratio = img_w / ocr_w\n",
    "\n",
    "    return img.crop([x * aspect_ratio for x in bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345343ab-b3aa-4eb0-ac77-68085045c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"../data\") / \"baseline_huggingface\"\n",
    "img_dir = out_dir / \"test\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_metadata = test_metadata.query(\"~pliktmonografi\")\n",
    "save_metadata = test_metadata[[\n",
    "    \"file_name\",\n",
    "    \"text\",\n",
    "    \"urn\",\n",
    "    \"langcodes\",\n",
    "    \"page\",\n",
    "    \"line\",\n",
    "]]\n",
    "save_metadata.to_csv(out_dir / \"metadata.csv\")\n",
    "save_metadata.assign(file_name=save_metadata[\"file_name\"].map(lambda x: Path(x).name)).to_csv(img_dir / \"_metadata.csv\")\n",
    "\n",
    "tm = test_metadata#.groupby(\"alto_dir\").apply(lambda x: pd.concat([x.head(1), x.tail(1)]))\n",
    "count = 0\n",
    "for row in tqdm(tm.itertuples(), total=len(tm)):\n",
    "    img_path = out_dir / row.file_name\n",
    "    img = crop_image(get_jp2_file(row.alto_file), row.bbox, row.img_size)\n",
    "    img.save(img_path)\n",
    "    \n",
    "    if (cer := compute_cer(row.text, row.transcription)) > 0.5:\n",
    "        img.thumbnail((1000, 200))\n",
    "        display(row.alto_file, row.text, row.transcription, cer,img)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9b96a-446c-4706-bce1-c531dc0339cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"../data/alto-jp2/avvir_null_null_20171230_10_248_1_jp2/avvir_null_null_20171230_10_248_1-1_004_null.jp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561e93d-8332-475c-bc77-747d81132907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
